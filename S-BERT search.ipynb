{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('msmarco-distilbert-base-dot-prod-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            article\n",
       "0  17307  PARIS  ?   When the Islamic State was about to...\n",
       "1  17292  Angels are everywhere in the Mu?iz family?s ap...\n",
       "2  17298  Finally. The Second Avenue subway opened in Ne...\n",
       "3  17311  WASHINGTON  ?   It?s   or   time for Republica...\n",
       "4  17339  For Megyn Kelly, the shift from Fox News to NB..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('news_dataset.csv', encoding='latin-1')\n",
    "data = df[['id', 'article']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>17313</td>\n",
       "      <td>The body of the Iraqi prisoner was found naked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>17545</td>\n",
       "      <td>DETROIT  ?   Just before the holidays, on a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>17546</td>\n",
       "      <td>DETROIT  ?   Just before the holidays, on a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>18185</td>\n",
       "      <td>The body of the Iraqi prisoner was found naked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>18186</td>\n",
       "      <td>The body of the Iraqi prisoner was found naked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>18337</td>\n",
       "      <td>HOUSTON  ?   The chants rang out loud and long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>18338</td>\n",
       "      <td>HOUSTON  ?   The chants rang out loud and long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>18339</td>\n",
       "      <td>Picking the pain reliever that?s best for you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>18341</td>\n",
       "      <td>Picking the pain reliever that?s best for you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            article\n",
       "41   17313  The body of the Iraqi prisoner was found naked...\n",
       "219  17545  DETROIT  ?   Just before the holidays, on a da...\n",
       "220  17546  DETROIT  ?   Just before the holidays, on a da...\n",
       "752  18185  The body of the Iraqi prisoner was found naked...\n",
       "753  18186  The body of the Iraqi prisoner was found naked...\n",
       "886  18337  HOUSTON  ?   The chants rang out loud and long...\n",
       "887  18338  HOUSTON  ?   The chants rang out loud and long...\n",
       "888  18339  Picking the pain reliever that?s best for you ...\n",
       "889  18341  Picking the pain reliever that?s best for you ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(subset=['article'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            article\n",
       "0  17307  PARIS  ?   When the Islamic State was about to...\n",
       "1  17292  Angels are everywhere in the Mu?iz family?s ap...\n",
       "2  17298  Finally. The Second Avenue subway opened in Ne...\n",
       "3  17311  WASHINGTON  ?   It?s   or   time for Republica...\n",
       "4  17339  For Megyn Kelly, the shift from Fox News to NB..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_dup = data.drop_duplicates(subset=['article'],keep='first').reset_index(drop=True)\n",
    "data_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean data\n",
    "def clean_text(text):\n",
    "    # Remove non-ASCII characters\n",
    "    text = ''.join([char for char in text if ord(char) < 128])\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove question mark problems\n",
    "    text = re.sub(r'(\\s\\?)',' ',text)\n",
    "    text = re.sub(r\"\\b\\?\\b\", \"\\'\", text)\n",
    "    text = re.sub(r\"(,\\?)\",\",\", text)\n",
    "    text = re.sub(r\"\\?+\", \"?\", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(data_index, data_text, chunk_size, chunk_overlap):\n",
    "\n",
    "    list_chunk_text = []\n",
    "\n",
    "    for position in range(len(data_index)):\n",
    "\n",
    "        words = clean_text(data_text[position]).split()\n",
    "\n",
    "        start = 0\n",
    "        part = 1\n",
    "        while start < len(words):\n",
    "            end = start + chunk_size\n",
    "            segment = ' '.join(words[start:end])\n",
    "            list_chunk_text.append((str(data_index[position]) + str(part), segment))\n",
    "            part += 1\n",
    "            start += (chunk_size - chunk_overlap)\n",
    "\n",
    "    return pd.DataFrame(list_chunk_text, columns=['id', 'article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = chunk_text(data_no_dup['id'], data_no_dup['article'], 500, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173071</td>\n",
       "      <td>PARIS When the Islamic State was about to be d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173072</td>\n",
       "      <td>to mobilize public opinion in the face of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173073</td>\n",
       "      <td>the guards at Mari reported that looters had c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172921</td>\n",
       "      <td>Angels are everywhere in the Mu'iz family's ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172922</td>\n",
       "      <td>and his lower jaw and cut a hole through his e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            article\n",
       "0  173071  PARIS When the Islamic State was about to be d...\n",
       "1  173072  to mobilize public opinion in the face of the ...\n",
       "2  173073  the guards at Mari reported that looters had c...\n",
       "3  172921  Angels are everywhere in the Mu'iz family's ap...\n",
       "4  172922  and his lower jaw and cut a hole through his e..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_info(dataframe_idx, score):\n",
    "    info = data_chunk.iloc[dataframe_idx]\n",
    "    meta_dict = {}\n",
    "    meta_dict['id'] = info['id']\n",
    "    meta_dict['article'] = info['article']\n",
    "    meta_dict['score'] = score\n",
    "    return meta_dict\n",
    "\n",
    "    \n",
    "def search(query, top_k, index, model):\n",
    "    query_vector = model.encode([query])\n",
    "    top_k = index.search(query_vector, top_k)\n",
    "    top_k_ids = list(top_k[1].tolist()[0])\n",
    "    score = list(top_k[0].tolist()[0])\n",
    "    results =  [fetch_data_info(idx, score) for idx, score in zip(top_k_ids, score)]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_chunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(encoded_data\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:350\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    347\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 350\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:822\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    820\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[1;32m--> 822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:587\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    579\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    580\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    581\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    584\u001b[0m         output_attentions,\n\u001b[0;32m    585\u001b[0m     )\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:531\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    528\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_layer_norm(sa_output \u001b[38;5;241m+\u001b[39m x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    532\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer_norm(ffn_output \u001b[38;5;241m+\u001b[39m sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    534\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:466\u001b[0m, in \u001b[0;36mFFN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:471\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    469\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    470\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[1;32m--> 471\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\Music\\2024 Tri 1_Applied NLP\\NLP_Assignment_2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoded_data = model.encode(data_chunk['article'].tolist())\n",
    "encoded_data = np.asarray(encoded_data.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "index.add_with_ids(encoded_data, np.array(range(0, len(data_chunk))))\n",
    "faiss.write_index(index, 'data_article.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "index = faiss.read_index('data_article.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '175741',\n",
       "  'article': \"SEOUL, South Korea A special prosecutor investigating the corruption scandal that led to President Park s impeachment summoned the de facto head of Samsung for questioning on Wednesday, calling him a bribery suspect. The de facto leader, Jay Y. Lee, the vice chairman of Samsung, will be questioned on Thursday, according to the special prosecutor's office, which recommended that he also be investigated on suspicion of perjury. Mr. Lee effectively runs Samsung, South Korea's largest conglomerate he is the son of its chairman, Lee who has been incapacitated with health problems. He is expected to be asked whether donations that Samsung made to two foundations controlled by Choi a longtime friend of the president, amounted to bribes, and what role, if any, he played in the decision to give the money. Investigators at the special prosecutor's office have questioned other senior Samsung executives as suspects about the bribery accusations. Neither Samsung nor Mr. Lee responded immediately to the announcement on Wednesday. Allegations that Ms. Park helped Ms. Choi extort millions in bribes from Samsung and other companies are at the heart of the corruption scandal that led to the National Assembly's vote to impeach her last month. Since then, Ms. Park's powers have been suspended, and she is on trial at the Constitutional Court, which will ultimately decide whether to end her presidency. Last month, Mr. Lee testified at a National Assembly hearing that he was not involved in the decision by Samsung to make the donations. He also said that the donations were not voluntary, suggesting that the company was a victim of extortion, not a participant in bribery. The reference on Wednesday to possible perjury charges against Mr. Lee stemmed from that testimony. The special prosecutor's office said it had evidence that Mr. Lee had received a request for bribery from the president and ordered Samsung subsidiaries to send bribes to destinations designated by the president. It asked the National Assembly to file a perjury complaint against Mr. Lee, which would authorize the special prosecutor to open an investigation of that charge. Asked whether investigators would seek to arrest Mr. Lee on bribery charges, a spokesman for the special prosecutor's office, Lee said, All possibilities are open. In November, state prosecutors indicted Ms. Choi on charges of coercing 53 big businesses, including Samsung, to contribute $69 million to her two foundations. They identified Ms. Park as an accomplice but stopped short of filing any charges against the businesses, all of which insisted that they were under government pressure to donate. In its impeachment bill, the National Assembly asserted that the donations were bribes, made with the expectation of political favors from the president. The special prosecutor, which took over the investigations from the state prosecutors last month, has been looking into possible bribery charges against not only Ms. Park but the businesses, particularly Samsung. Ms. Park cannot be indicted while in office. Samsung gave the largest donations to Ms. Choi's foundations, totaling $17 million. Unlike the other corporate\",\n",
       "  'score': 53.68763732910156},\n",
       " {'id': '178513',\n",
       "  'article': \"said Don Rosenberg, a lawyer for Qualcomm. The regulators, he said, were prodded and misled by commercial interests. In an email, Jee, a spokeswoman for Samsung, said it was one of many multinational corporations? that responded to questions from South Korean regulators. Qualcomm's lawyer figures the Korean case may take years to move through the courts. And recent events, including the impeachment of South Korea's president and a bribery scandal at Samsung, could complicate, or eliminate, Qualcomm's regulatory issues there. Additionally, the F. T. C. has just three of its normal five commissioners. One of those, Maureen Ohlhausen, a Republican, voted against the suit. She may be named chairwoman when the current chairwoman, Edith Ramirez, a Democrat, steps down on Feb. 10. Neither the F. T. C. nor Apple would comment on the United States case against Qualcomm. It's disappointing when our partners want to pay less after we've contributed to their success, said Derek Aberle, Qualcomm's president. Now it must get out ahead of other technology inventors in 5G, possibly while paying billions in fines and dealing with a painful restructuring and fraying relationships with its biggest customers. We're not sitting still? while the problems are sorted, Mr. Aberle said. You have to invest, and invent cool stuff that will change the way people live their lives. In other words, create unique technology so people will keep paying for Qualcomm's expensive intellectual property.\",\n",
       "  'score': 50.570491790771484},\n",
       " {'id': '177641',\n",
       "  'article': \"SEOUL, South Korea A South Korean court on Thursday blocked a prosecutor's attempt to arrest Jay Y. Lee, the leader of Samsung, saying there was not enough evidence that Mr. Lee had bribed President Park in a scandal that led to her impeachment. A justice on the Central District Court in Seoul, Cho rejected the prosecutor's request to issue an arrest warrant, saying said it was difficult to recognize the need? to incarcerate Mr. Lee. Mr. Lee, a scion and vice chairman of Samsung, one of the world's biggest conglomerates, was immediately released from a detention center outside Seoul, where he had been waiting for the court to decide whether he should be formally arrested. South Koreans have paid keen attention to the fate of Mr. Lee. Some analysts said his case was a test of whether the country's relatively youthful democracy and judicial system are ready to crack down on the crimes of conglomerates. No Samsung leader has ever been jailed, though the company has been investigated many times for corruption. The court's decision is likely to anger many South Koreans who have held weekend rallies calling for Ms. Park's ouster and the arrest of business tycoons on corruption charges. The special prosecutor called the court decision very regrettable. But he has yet to announce whether he will offer more evidence in a renewed effort to have Mr. Lee arrested. He can also indict Mr. Lee on bribery or lesser charges without arresting him. We will take necessary steps and persist in our investigation without wavering, said Lee a spokesman for the special prosecutor, without elaborating. Samsung welcomed the court's decision. For now, the ruling allows Mr. Lee to continue to lead Samsung. It dealt a blow to the special prosecutor who had tried to build a bribery case against Mr. Lee and Ms. Park. Mr. Lee's father has twice been convicted of bribery and tax evasion but has never spent a day in prison. Each time, he received a presidential pardon and returned to management. Mr. Lee, 48, was accused of paying $36 million to Ms. Park's secretive confidante, Choi . The special prosecutor and Mr. Lee's lawyers have been arguing over how to characterize the money. In November, state prosecutors indicted Ms. Choi on extortion charges, saying she leveraged her connections with Ms. Park to coerce Samsung and scores of other big businesses to contribute tens of millions of dollars to two foundations Ms. Choi controlled or to companies run by her or her associates. They identified Ms. Park as an accomplice, but they brought no charges against the businesses, which they saw as victims of extortion. But the special prosecutor, Park who took over the investigation from state prosecutors last month, has called Samsung's contributions bribes that were exchanged for political favors from Ms. Park. That includes government support for a merger of two Samsung affiliates in 2015, which helped Mr. Lee inherit corporate control from his incapacitated father, the chairman, Lee according to the prosecutor.\",\n",
       "  'score': 49.18482208251953},\n",
       " {'id': '177642',\n",
       "  'article': \"from state prosecutors last month, has called Samsung's contributions bribes that were exchanged for political favors from Ms. Park. That includes government support for a merger of two Samsung affiliates in 2015, which helped Mr. Lee inherit corporate control from his incapacitated father, the chairman, Lee according to the prosecutor. groups accused the prosecutor of overreaching in an attempt to find a scapegoat to soothe a public infuriated over Ms. Park's corruption scandal and fed up with decades of collusive ties between the government and the chaebol. Mr. Lee was the most prominent businessman to be ensnared in the special prosecutor's broadening investigation into the corruption scandal that led to Ms. Park's impeachment by Parliament last month. Ms. Park's presidential powers remained suspended, while the Constitutional Court is expected to rule in coming weeks whether she should be reinstated or formally removed from office. We have been too lenient toward chaebol corruption, said Moon an opposition politician who leads in polls on contenders to replace Ms. Park if she is removed. Speaking to a group of foreign reporters hours before the court's decision, Mr. Moon said Samsung was typical of a chaebol whose top boss wielded imperial powers? over his sprawling business group but was seldom held accountable? for corruption or managerial failures. Ms. Park denies any wrongdoing. Mr. Lee and Samsung have also denied bribery they argued that the donations? Samsung paid out to Ms. Choi were coerced, not meant as a quid pro quo for political favors from Ms. Park.\",\n",
       "  'score': 47.49772644042969},\n",
       " {'id': '175742',\n",
       "  'article': \"over the investigations from the state prosecutors last month, has been looking into possible bribery charges against not only Ms. Park but the businesses, particularly Samsung. Ms. Park cannot be indicted while in office. Samsung gave the largest donations to Ms. Choi's foundations, totaling $17 million. Unlike the other corporate contributors, it went beyond support for the foundations, signing an $18 million contract with a sports management company that Ms. Choi ran in Germany, to fund a program for training Korean equestrians, which mainly benefited Ms. Choi's daughter. Samsung also contributed $1. 3 million to a winter sports program for young athletes that Ms. Choi and her nephew ran. Also on Wednesday, the special prosecutor's office said it had acquired a tablet computer used by Ms. Choi that contained emails she exchanged with a Samsung executive. The emails contained information about the financial support provided by Samsung, the prosecutor's office said. The special prosecutor has been investigating whether Samsung gave its support to Ms. Choi in exchange for a decision by the National Pension Service to support a contentious merger of two Samsung affiliates in 2015. Moon chairman of the pension fund, was arrested last month on charges that he illegally pressured the fund to back that merger when he was South Korea's health and welfare minister. The national pension fund's support was crucial for the merger, which analysts said helped Mr. Lee inherit control of Samsung from his father.\",\n",
       "  'score': 44.042579650878906},\n",
       " {'id': '173541',\n",
       "  'article': \"The Wall Street lawyer Walter J. Clayton does not travel in political circles, nor is he well known in corporate America. He is the insider's insider a deal maker. As such, his nomination to lead the Securities and Exchange Commission is a strong signal that financial regulation in the Trump administration will emphasize helping companies raise capital in the public markets over tightening regulation. In contrast, the agency's two chairwomen under President Obama had regulatory or enforcement backgrounds. Mr. Clayton, known as Jay, has spent nearly his entire career in corporate boardrooms. His regulatory experience stems from advising banks on dealings with the government and helping several financial institutions with their settlements related to mortgage securities. He had a seat to the financial crisis, advising Barclays Capital in buying the assets of the bankrupt Lehman Brothers in 2008 and Bear Stearns in its fire sale to JPMorgan Chase in 2007. He has advised on mergers and initial public offerings, including the biggest ever, the $25 billion offering by Alibaba Group of China in 2013. If Mr. Clayton is confirmed, he may have to recuse himself from some matters. A similar scrutiny was applied to Mary Jo White, the agency's current chairwoman. She had been a litigator at Debevoise Plimpton, where her clients included JPMorgan Chase, Rupert Murdoch's News Corporation and Kenneth D. Lewis, a former Bank of America chief executive. Still, such recusals are not unusual. Laura S. Unger, a former commissioner and acting chairwoman, said that during her tenure, she had to recuse herself from a number of matters before the commission. She said the process of deciding when to recuse oneself often took place in consultation with the commission's ethics officer. An ethics officer at the S. E. C. knows all of your intimate details, and the ethics officer flags for you what may be potential conflicts, she noted. Yet Mr. Clayton's nomination will be sure to fuel criticism that Goldman Sachs could wield too much influence in the Trump administration. Sullivan Cromwell, where Mr. Clayton is a partner, has been Goldman's law firm for more than a century. Mr. Clayton advised Goldman Sachs on perhaps its most important deal, the $5 billion investment by Warren E. Buffett's Berkshire Hathaway amid the financial crisis. Mr. Clayton's wife works as a adviser at Goldman. The S. E. C. nomination follows the appointment of Goldman's No. 2 executive, Gary D. Cohn, to be the top economic policy adviser to Donald J. Trump, and the selection of a hedge fund manager who was a former Goldman trader, Steven T. Mnuchin, to be Treasury secretary. Mr. Trump's chief strategist, Stephen K. Bannon, is a former Goldman banker. During the presidential campaign, Mr. Trump had repeatedly criticized Goldman Sachs as an emblem of a financial elite. Mr. Trump, who met with Mr. Clayton on Dec. 22, said in a statement that the lawyer will ensure our financial institutions can thrive and create jobs while playing by the rules at the same time. Mr.\",\n",
       "  'score': 43.05010223388672},\n",
       " {'id': '182601',\n",
       "  'article': \"SEOUL, South Korea The chief of North Korea's powerful secret police, long considered the man for the top leader, Kim has been dismissed on charges of corruption and abuse of power, the South Korean government said on Friday. The firing of the chief, Gen. Kim as minister of state security highlights the turmoil that has engulfed the upper reaches of Mr. Kim's government. The general is the latest in a series of party and military officials Mr. Kim has fired, demoted or executed as he tried to consolidate his totalitarian power through what South Korean officials and North Korean defectors have called a reign of terror. General Kim was fired in after he was demoted to a general from a one, said Jeong a spokesman for the South's Unification Ministry. The general's surprise downfall was the latest indication that even top lieutenants are at risk as Mr. Kim has rival agencies monitor one another to detect and punish any sign of disrespect or disloyalty. Until his dismissal, General Kim had been Mr. Kim's chief henchman in purging potential enemies. Kim has been a key aide to Kim and has buttressed his reign of terror, Mr. Jeong said. His dismissal could further deepen unrest among officials and add to the instability of the regime by weakening its control on the people. Mr. Jeong said General Kim was accused of corruption and held responsible for various human rights violations, including torture, committed at his agency. But other political machinations could be at play behind the dismissal, Mr. Jeong said, citing speculation about a rivalry among different power centers. Mr. Jeong noted that the dismissal resulted from an investigation by another powerful agency, the Organization and Guidance Department of the governing Workers? Party of North Korea. The department supervises all state agencies and is reportedly directly overseen by Mr. Kim. The Organization and Guidance Department is conducting an intensive investigation of Kim and the Ministry of State Security, so the level of punishment and the number of people affected could be expanded, Mr. Jeong said, without disclosing how the South Korean government learned of the reported purge transpiring inside a secretive regime. The Ministry of State Security, which serves as the secret police and intelligence agency in the North, is one of the most feared tools of government there, responsible for arresting dissidents and running a network of prison gulags. When Mr. Kim executed his own uncle and No. 2 official, Jang on charges of factionalism, corruption and plotting to overthrow his government in 2013, it was General Kim's ministry that arrested and Mr. Jang. Since taking power after the death of his father in 2011, Mr. Kim has frequently reshuffled the party and military elites as he has moved swiftly to establish his monolithic authority in North Korea, which his family has ruled for seven decades. Mr. Kim has executed at least 140 senior officials, usually killing them with machine guns and even flamethrowers, according to the Institute for National Security Strategy,\",\n",
       "  'score': 42.99745178222656},\n",
       " {'id': '178303',\n",
       "  'article': \"Brothers in trouble, is all over prime time, even on comedies like . And now comes Donald J. Trump, who seems to have thin skin. The Smotherses incurred the wrath of two presidents, Lyndon B. Johnson and Richard M. Nixon. Tom Smothers, who turns 80 in February, said in an interview in 2000 that he had always believed Nixon was directly responsible for his show's demise. There was a bigger game going on that was beyond our scope of understanding, he said. Who knows what games lie ahead as a Twitter president takes office?\",\n",
       "  'score': 42.86895751953125},\n",
       " {'id': '181143',\n",
       "  'article': \"including some of the women in the department. Among them is Anne Patterson, 67, the assistant secretary of state for Near Eastern affairs and a former ambassador to Pakistan and Egypt, two of the biggest tinderboxes Mr. Trump will face. Victoria J. Nuland, 55, one of the department's top Russia experts and former ambassador to NATO, who dealt with the Ukraine crisis, decided to retire after concluding there was probably no place for her in Mr. Trump's administration. Such a housecleaning leaves open the question of whether Mr. Tillerson, who has extensive experience abroad as chief executive of Exxon Mobil but none as a diplomat, will have the kind of help he needs in a very different kind of enterprise than negotiating on behalf of the world's largest oil company. In such an atmosphere, even seemingly routine moves like the reorganization of the National Security Council take on a political air. On Sunday, Mr. Trump's chief strategist, and chief ideologue, Stephen K. Bannon, was designated a permanent member of the principals committee? of the National Security Council, putting a political aide on par with the secretaries of state and defense. Meanwhile, the director of national intelligence and the chairman of the Joint Chiefs of Staff appeared to be downgraded, told to attend only when their issues were on the table. This is stone cold crazy, Susan E. Rice, the national security adviser until earlier this month, wrote in a Twitter post. Who needs military advice or intell to make policy on ISIL, Syria, Afghanistan, DPRK? she said, using acronyms for the Islamic State and North Korea. Mr. Trump's answer is simple: When you have come to upend the establishment, the establishment must vacate the premises.\",\n",
       "  'score': 42.8021240234375},\n",
       " {'id': '180683',\n",
       "  'article': \"the country's reputation and values. Microsoft was not the only company to become bolder in a few hours. Around 10 a. m. on Saturday, Mr. Chesky of Airbnb posted a vague message on Twitter saying open doors bring all of US together. By 6 p. m. he was advocating open protest. Early Sunday morning, he wrote a memo to employees warning that Mr. Trump's new policy was a direct obstacle to our mission. It was a long, dizzying day for an industry that is struggling to find its footing under the new president. It feels like the air itself has changed, like when a storm comes, said Shervin Pishevar, a founder of Sherpa Capital and Hyperloop One. Even before the executive order, pressure had been building on companies to speak out against measures being endorsed by Mr. Trump. Some of that impetus came from employees, and some from activists. Engineers and product managers at several tech companies spoke to The New York Times on the condition of anonymity. They have signed nondisclosure agreements at their companies and are generally not authorized to speak to the news media. At Twitter, a number of workers felt frustrated with the disconnect between their company's product a platform for free speech and the extent to which Mr. Trump has used it to attack those who question him and proclaim outright falsehoods to the American public. On Saturday, Jack Dorsey, Twitter's chief executive, posted and reposted numerous messages denouncing the travel ban. At Facebook, employees felt a similar sense of discord. Some complained about how long it took Mr. Zuckerberg and Sheryl Sandberg, the chief operating officer, to speak out. Others were upset at the continued presence of Peter Thiel, a venture capitalist and a longtime confidant of Mr. Zuckerberg's, as a director on Facebook's board. Mr. Thiel was a donor to Mr. Trump?s campaign and has since become an adviser, and he issued a statement on Saturday evening that reaffirmed his support for the president. Uber is under one of the brightest spotlights. Travis Kalanick, its chief executive, is part of Mr. Trump's economic advisory team. That has made Uber a target of protesters, some of whom shut down access to its headquarters on Inauguration Day. In an email to employees on Saturday titled Standing up for what's right, Mr. Kalanick stressed the importance of pushing for change by working to have a seat at the table and discussing any differences. He said he would be seeing Mr. Trump on Friday. As protesters at Kennedy International Airport in New York multiplied on Saturday night, cabdrivers largely immigrants began a work stoppage at the airport as a form of protest against the executive order. Uber did not follow suit. Instead, it posted on Twitter that it was suspending surge pricing at Kennedy Airport. That prompted accusations that it was trying to break the strike, which the company awkwardly denied in another Twitter post. On Sunday morning, its competitor Lyft said it was donating $1 million\",\n",
       "  'score': 42.4063835144043}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is the vice chairman of Samsung?\"\n",
    "query = clean_text(query)\n",
    "results = search(query, top_k=10, index=index, model=model)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_score(model_inputs):\n",
    "    scores = cross_model.predict(model_inputs)\n",
    "    return scores\n",
    "\n",
    "model_inputs = [[query, item['article']] for item in results]\n",
    "scores = cross_score(model_inputs)\n",
    "\n",
    "#Sort the scores in decreasing order\n",
    "ranked_results = [{'Id': inp['id'], 'Score': score} for inp, score in zip(results, scores)]\n",
    "ranked_results = sorted(ranked_results, key=lambda x: x['Score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'Id': '175741', 'Score': 0.95794976}\n",
      "\t None\n",
      "{'Id': '177641', 'Score': 0.12907586}\n",
      "\t None\n",
      "{'Id': '177642', 'Score': 0.053180993}\n",
      "\t None\n",
      "{'Id': '178513', 'Score': 0.0005532388}\n",
      "\t None\n",
      "{'Id': '175742', 'Score': 0.00019425723}\n",
      "\t None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"\\n\")\n",
    "for result in ranked_results[:5]:\n",
    "    print('\\t',pprint(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'Id': '179103', 'Score': 0.00019763244}\n",
      "\t None\n",
      "{'Id': '183542', 'Score': 0.00018770898}\n",
      "\t None\n",
      "{'Id': '183343', 'Score': 0.0001814828}\n",
      "\t None\n",
      "{'Id': '181331', 'Score': 0.00016951578}\n",
      "\t None\n",
      "{'Id': '176332', 'Score': 0.00016916702}\n",
      "\t None\n"
     ]
    }
   ],
   "source": [
    "query = \"who lives in Sheepshead Bay?\"\n",
    "query = clean_text(query)\n",
    "results = search(query, top_k=10, index=index, model=model)\n",
    "model_inputs = [[query, item['article']] for item in results]\n",
    "scores = cross_score(model_inputs)\n",
    "\n",
    "ranked_results = [{'Id': inp['id'], 'Score': score} for inp, score in zip(results, scores)]\n",
    "ranked_results = sorted(ranked_results, key=lambda x: x['Score'], reverse=True)\n",
    "print(\"\\n\")\n",
    "for result in ranked_results[:5]:\n",
    "    print('\\t',pprint(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the vice chairman of Samsung?\"\n",
    "query = clean_text(query)\n",
    "ranked_results_bert = []\n",
    "\n",
    "for result in results:\n",
    "    P, R, F1 = score([result['article']], [query], lang='en')\n",
    "    ranked_results_bert.append({'Id': result['id'], 'Score': F1.numpy()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'Id': '175943', 'Score': 0.8234369}\n",
      "\t None\n",
      "{'Id': '175501', 'Score': 0.820606}\n",
      "\t None\n",
      "{'Id': '181351', 'Score': 0.8139641}\n",
      "\t None\n",
      "{'Id': '183661', 'Score': 0.81344926}\n",
      "\t None\n",
      "{'Id': '181331', 'Score': 0.81143385}\n",
      "\t None\n"
     ]
    }
   ],
   "source": [
    "ranked_results_bert = sorted(ranked_results_bert, key=lambda x: x['Score'], reverse=True)\n",
    "print(\"\\n\")\n",
    "for result in ranked_results_bert[:5]:\n",
    "    print('\\t',pprint(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
