{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('msmarco-distilbert-base-dot-prod-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            article\n",
       "0  17307  PARIS  ?   When the Islamic State was about to...\n",
       "1  17292  Angels are everywhere in the Mu?iz family?s ap...\n",
       "2  17298  Finally. The Second Avenue subway opened in Ne...\n",
       "3  17311  WASHINGTON  ?   It?s   or   time for Republica...\n",
       "4  17339  For Megyn Kelly, the shift from Fox News to NB..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('news_dataset.csv', encoding='latin-1')\n",
    "data = df[['id', 'article']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>17313</td>\n",
       "      <td>The body of the Iraqi prisoner was found naked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>17545</td>\n",
       "      <td>DETROIT  ?   Just before the holidays, on a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>17546</td>\n",
       "      <td>DETROIT  ?   Just before the holidays, on a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>18185</td>\n",
       "      <td>The body of the Iraqi prisoner was found naked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>18186</td>\n",
       "      <td>The body of the Iraqi prisoner was found naked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>18337</td>\n",
       "      <td>HOUSTON  ?   The chants rang out loud and long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>18338</td>\n",
       "      <td>HOUSTON  ?   The chants rang out loud and long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>18339</td>\n",
       "      <td>Picking the pain reliever that?s best for you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>18341</td>\n",
       "      <td>Picking the pain reliever that?s best for you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            article\n",
       "41   17313  The body of the Iraqi prisoner was found naked...\n",
       "219  17545  DETROIT  ?   Just before the holidays, on a da...\n",
       "220  17546  DETROIT  ?   Just before the holidays, on a da...\n",
       "752  18185  The body of the Iraqi prisoner was found naked...\n",
       "753  18186  The body of the Iraqi prisoner was found naked...\n",
       "886  18337  HOUSTON  ?   The chants rang out loud and long...\n",
       "887  18338  HOUSTON  ?   The chants rang out loud and long...\n",
       "888  18339  Picking the pain reliever that?s best for you ...\n",
       "889  18341  Picking the pain reliever that?s best for you ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(subset=['article'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17307</td>\n",
       "      <td>PARIS  ?   When the Islamic State was about to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17292</td>\n",
       "      <td>Angels are everywhere in the Mu?iz family?s ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17298</td>\n",
       "      <td>Finally. The Second Avenue subway opened in Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17311</td>\n",
       "      <td>WASHINGTON  ?   It?s   or   time for Republica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17339</td>\n",
       "      <td>For Megyn Kelly, the shift from Fox News to NB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            article\n",
       "0  17307  PARIS  ?   When the Islamic State was about to...\n",
       "1  17292  Angels are everywhere in the Mu?iz family?s ap...\n",
       "2  17298  Finally. The Second Avenue subway opened in Ne...\n",
       "3  17311  WASHINGTON  ?   It?s   or   time for Republica...\n",
       "4  17339  For Megyn Kelly, the shift from Fox News to NB..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_no_dup = data.drop_duplicates(subset=['article'],keep='first').reset_index(drop=True)\n",
    "data_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean data\n",
    "def clean_text(text):\n",
    "    # Remove non-ASCII characters\n",
    "    text = ''.join([char for char in text if ord(char) < 128])\n",
    "\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove question mark problems\n",
    "    text = re.sub(r'(\\s\\?)',' ',text)\n",
    "    text = re.sub(r\"\\b\\?\\b\", \"\\'\", text)\n",
    "    text = re.sub(r\"(,\\?)\",\",\", text)\n",
    "    text = re.sub(r\"\\?+\", \"?\", text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(data_index, data_text, chunk_size, chunk_overlap):\n",
    "\n",
    "    list_chunk_text = []\n",
    "\n",
    "    for position in range(len(data_index)):\n",
    "\n",
    "        words = clean_text(data_text[position]).split()\n",
    "\n",
    "        start = 0\n",
    "        part = 1\n",
    "        while start < len(words):\n",
    "            end = start + chunk_size\n",
    "            segment = ' '.join(words[start:end])\n",
    "            list_chunk_text.append((str(data_index[position]) + str(part), segment))\n",
    "            part += 1\n",
    "            start += (chunk_size - chunk_overlap)\n",
    "\n",
    "    return pd.DataFrame(list_chunk_text, columns=['id', 'article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk = chunk_text(data_no_dup['id'], data_no_dup['article'], 500, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk.to_csv('data_chunk.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173071</td>\n",
       "      <td>PARIS When the Islamic State was about to be d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173072</td>\n",
       "      <td>to mobilize public opinion in the face of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173073</td>\n",
       "      <td>the guards at Mari reported that looters had c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172921</td>\n",
       "      <td>Angels are everywhere in the Mu'iz family's ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172922</td>\n",
       "      <td>and his lower jaw and cut a hole through his e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                            article\n",
       "0  173071  PARIS When the Islamic State was about to be d...\n",
       "1  173072  to mobilize public opinion in the face of the ...\n",
       "2  173073  the guards at Mari reported that looters had c...\n",
       "3  172921  Angels are everywhere in the Mu'iz family's ap...\n",
       "4  172922  and his lower jaw and cut a hole through his e..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_info(dataframe_idx, score):\n",
    "    info = data_chunk.iloc[dataframe_idx]\n",
    "    meta_dict = {}\n",
    "    meta_dict['id'] = info['id']\n",
    "    meta_dict['article'] = info['article']\n",
    "    meta_dict['score'] = score\n",
    "    return meta_dict\n",
    "\n",
    "    \n",
    "def search(query, top_k, index, model):\n",
    "    query_vector = model.encode([query])\n",
    "    top_k = index.search(query_vector, top_k)\n",
    "    print(top_k)\n",
    "    top_k_ids = list(top_k[1].tolist()[0])\n",
    "    score = list(top_k[0].tolist()[0])\n",
    "    results =  [fetch_data_info(idx, score) for idx, score in zip(top_k_ids, score)]\n",
    "    return top_k_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = model.encode(data_chunk['article'].tolist())\n",
    "encoded_data = np.asarray(encoded_data.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "index.add_with_ids(encoded_data, np.array(range(0, len(data_chunk))))\n",
    "faiss.write_index(index, 'data_article.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "index = faiss.read_index('data_article.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexIDMap; proxy of <Swig Object of type 'faiss::IndexIDMapTemplate< faiss::Index > *' at 0x00000122C680FA80> >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[53.687637, 50.57049 , 49.184822, 47.497726, 44.04258 , 43.050102,\n",
      "        42.99745 , 42.868958, 42.802124, 42.406384, 42.37947 , 41.848022,\n",
      "        41.833664, 41.7257  , 41.68076 , 41.54087 , 41.514153, 41.352108,\n",
      "        41.108116, 40.851246]], dtype=float32), array([[ 714, 1444, 1215, 1216,  715,  172, 2446, 1381, 2089, 2027, 2392,\n",
      "        2911,  872,  675,  787, 1741, 1307, 2627, 2407,  159]],\n",
      "      dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[714,\n",
       " 1444,\n",
       " 1215,\n",
       " 1216,\n",
       " 715,\n",
       " 172,\n",
       " 2446,\n",
       " 1381,\n",
       " 2089,\n",
       " 2027,\n",
       " 2392,\n",
       " 2911,\n",
       " 872,\n",
       " 675,\n",
       " 787,\n",
       " 1741,\n",
       " 1307,\n",
       " 2627,\n",
       " 2407,\n",
       " 159]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is the vice chairman of Samsung?\"\n",
    "query = clean_text(query)\n",
    "results = search(query, top_k=20, index=index, model=model)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_model = CrossEncoder('cross-encoder/ms-marco-TinyBERT-L-6', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     scores \u001b[38;5;241m=\u001b[39m cross_model\u001b[38;5;241m.\u001b[39mpredict(model_inputs)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n\u001b[1;32m----> 5\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_score(model_inputs)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Sort the scores in decreasing order\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m     scores \u001b[38;5;241m=\u001b[39m cross_model\u001b[38;5;241m.\u001b[39mpredict(model_inputs)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n\u001b[1;32m----> 5\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m [[query, \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[0;32m      6\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_score(model_inputs)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Sort the scores in decreasing order\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "def cross_score(model_inputs):\n",
    "    scores = cross_model.predict(model_inputs)\n",
    "    return scores\n",
    "\n",
    "model_inputs = [[query, item['article']] for item in results]\n",
    "scores = cross_score(model_inputs)\n",
    "\n",
    "#Sort the scores in decreasing order\n",
    "ranked_results = [{'Id': inp['id'], 'Score': score} for inp, score in zip(results, scores)]\n",
    "ranked_results = sorted(ranked_results, key=lambda x: x['Score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'Id': '175741', 'Score': 0.95794976}\n",
      "\t None\n",
      "{'Id': '177641', 'Score': 0.12907586}\n",
      "\t None\n",
      "{'Id': '177642', 'Score': 0.053180993}\n",
      "\t None\n",
      "{'Id': '178513', 'Score': 0.0005532388}\n",
      "\t None\n",
      "{'Id': '175742', 'Score': 0.00019425723}\n",
      "\t None\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"\\n\")\n",
    "for result in ranked_results[:5]:\n",
    "    print('\\t',pprint(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'Id': '179103', 'Score': 0.00019763244}\n",
      "\t None\n",
      "{'Id': '183542', 'Score': 0.00018770898}\n",
      "\t None\n",
      "{'Id': '183343', 'Score': 0.0001814828}\n",
      "\t None\n",
      "{'Id': '181331', 'Score': 0.00016951578}\n",
      "\t None\n",
      "{'Id': '176332', 'Score': 0.00016916702}\n",
      "\t None\n"
     ]
    }
   ],
   "source": [
    "query = \"who lives in Sheepshead Bay?\"\n",
    "query = clean_text(query)\n",
    "results = search(query, top_k=10, index=index, model=model)\n",
    "model_inputs = [[query, item['article']] for item in results]\n",
    "scores = cross_score(model_inputs)\n",
    "\n",
    "ranked_results = [{'Id': inp['id'], 'Score': score} for inp, score in zip(results, scores)]\n",
    "ranked_results = sorted(ranked_results, key=lambda x: x['Score'], reverse=True)\n",
    "print(\"\\n\")\n",
    "for result in ranked_results[:5]:\n",
    "    print('\\t',pprint(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the vice chairman of Samsung?\"\n",
    "query = clean_text(query)\n",
    "ranked_results_bert = []\n",
    "\n",
    "for result in results:\n",
    "    P, R, F1 = score([result['article']], [query], lang='en')\n",
    "    ranked_results_bert.append({'Id': result['id'], 'Score': F1.numpy()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{'Id': '175943', 'Score': 0.8234369}\n",
      "\t None\n",
      "{'Id': '175501', 'Score': 0.820606}\n",
      "\t None\n",
      "{'Id': '181351', 'Score': 0.8139641}\n",
      "\t None\n",
      "{'Id': '183661', 'Score': 0.81344926}\n",
      "\t None\n",
      "{'Id': '181331', 'Score': 0.81143385}\n",
      "\t None\n"
     ]
    }
   ],
   "source": [
    "ranked_results_bert = sorted(ranked_results_bert, key=lambda x: x['Score'], reverse=True)\n",
    "print(\"\\n\")\n",
    "for result in ranked_results_bert[:5]:\n",
    "    print('\\t',pprint(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
